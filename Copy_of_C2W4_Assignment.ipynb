{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d361bbd9",
      "metadata": {
        "id": "d361bbd9"
      },
      "source": [
        "# Week 4: Multi-class Classification\n",
        "\n",
        "Welcome to this assignment! In this exercise, you will get a chance to work on a multi-class classification problem. You will be using the [Sign Language MNIST](https://www.kaggle.com/datamunge/sign-language-mnist) dataset, which contains 28x28 images of hands depicting the 26 letters of the english alphabet. \n",
        "\n",
        "You will need to pre-process the data so that it can be fed into your convolutional neural network to correctly classify each image as the letter it represents.\n",
        "\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e97ccaec",
      "metadata": {
        "id": "e97ccaec"
      },
      "source": [
        "_**NOTE:** To prevent errors from the autograder, pleave avoid editing or deleting non-graded cells in this notebook . Please only put your solutions in between the `### START CODE HERE` and `### END CODE HERE` code comments, and refrain from adding any new cells._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8e09ac06",
      "metadata": {
        "id": "8e09ac06",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "import csv\n",
        "import string\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28d9421c",
      "metadata": {
        "id": "28d9421c"
      },
      "source": [
        "Download the training and test sets (the test set will actually be used as a validation set):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1ffc611",
      "metadata": {
        "id": "a1ffc611",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3f1313-dd88-407a-f244-213cdfcb25b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z0DkA9BytlLxO1C0BAWzknLyQmZAp0HR\n",
            "To: /content/sign_mnist_train.csv\n",
            "100% 83.3M/83.3M [00:02<00:00, 34.3MB/s]\n",
            "/usr/local/lib/python3.9/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z1BIj4qmri59GWBG4ivMNFtpZ4AXIbzg\n",
            "To: /content/sign_mnist_test.csv\n",
            "100% 21.8M/21.8M [00:00<00:00, 61.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# sign_mnist_train.csv\n",
        "!gdown --id 1z0DkA9BytlLxO1C0BAWzknLyQmZAp0HR\n",
        "# sign_mnist_test.csv\n",
        "!gdown --id 1z1BIj4qmri59GWBG4ivMNFtpZ4AXIbzg"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1216e2e",
      "metadata": {
        "id": "e1216e2e"
      },
      "source": [
        "Define some globals with the path to both files you just downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1b7007d2",
      "metadata": {
        "id": "1b7007d2",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "TRAINING_FILE = './sign_mnist_train.csv'\n",
        "VALIDATION_FILE = './sign_mnist_test.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c087ba57",
      "metadata": {
        "id": "c087ba57"
      },
      "source": [
        "Unlike previous assignments, you will not have the actual images provided, instead you will have the data serialized as `csv` files.\n",
        "\n",
        "Take a look at how the data looks like within the `csv` file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1d08a94d",
      "metadata": {
        "id": "1d08a94d",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988c6756-d6f3-4e8f-ba39-0cd554fd1e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First line (header) looks like this:\n",
            "label,pixel1,pixel2,pixel3,pixel4,pixel5,pixel6,pixel7,pixel8,pixel9,pixel10,pixel11,pixel12,pixel13,pixel14,pixel15,pixel16,pixel17,pixel18,pixel19,pixel20,pixel21,pixel22,pixel23,pixel24,pixel25,pixel26,pixel27,pixel28,pixel29,pixel30,pixel31,pixel32,pixel33,pixel34,pixel35,pixel36,pixel37,pixel38,pixel39,pixel40,pixel41,pixel42,pixel43,pixel44,pixel45,pixel46,pixel47,pixel48,pixel49,pixel50,pixel51,pixel52,pixel53,pixel54,pixel55,pixel56,pixel57,pixel58,pixel59,pixel60,pixel61,pixel62,pixel63,pixel64,pixel65,pixel66,pixel67,pixel68,pixel69,pixel70,pixel71,pixel72,pixel73,pixel74,pixel75,pixel76,pixel77,pixel78,pixel79,pixel80,pixel81,pixel82,pixel83,pixel84,pixel85,pixel86,pixel87,pixel88,pixel89,pixel90,pixel91,pixel92,pixel93,pixel94,pixel95,pixel96,pixel97,pixel98,pixel99,pixel100,pixel101,pixel102,pixel103,pixel104,pixel105,pixel106,pixel107,pixel108,pixel109,pixel110,pixel111,pixel112,pixel113,pixel114,pixel115,pixel116,pixel117,pixel118,pixel119,pixel120,pixel121,pixel122,pixel123,pixel124,pixel125,pixel126,pixel127,pixel128,pixel129,pixel130,pixel131,pixel132,pixel133,pixel134,pixel135,pixel136,pixel137,pixel138,pixel139,pixel140,pixel141,pixel142,pixel143,pixel144,pixel145,pixel146,pixel147,pixel148,pixel149,pixel150,pixel151,pixel152,pixel153,pixel154,pixel155,pixel156,pixel157,pixel158,pixel159,pixel160,pixel161,pixel162,pixel163,pixel164,pixel165,pixel166,pixel167,pixel168,pixel169,pixel170,pixel171,pixel172,pixel173,pixel174,pixel175,pixel176,pixel177,pixel178,pixel179,pixel180,pixel181,pixel182,pixel183,pixel184,pixel185,pixel186,pixel187,pixel188,pixel189,pixel190,pixel191,pixel192,pixel193,pixel194,pixel195,pixel196,pixel197,pixel198,pixel199,pixel200,pixel201,pixel202,pixel203,pixel204,pixel205,pixel206,pixel207,pixel208,pixel209,pixel210,pixel211,pixel212,pixel213,pixel214,pixel215,pixel216,pixel217,pixel218,pixel219,pixel220,pixel221,pixel222,pixel223,pixel224,pixel225,pixel226,pixel227,pixel228,pixel229,pixel230,pixel231,pixel232,pixel233,pixel234,pixel235,pixel236,pixel237,pixel238,pixel239,pixel240,pixel241,pixel242,pixel243,pixel244,pixel245,pixel246,pixel247,pixel248,pixel249,pixel250,pixel251,pixel252,pixel253,pixel254,pixel255,pixel256,pixel257,pixel258,pixel259,pixel260,pixel261,pixel262,pixel263,pixel264,pixel265,pixel266,pixel267,pixel268,pixel269,pixel270,pixel271,pixel272,pixel273,pixel274,pixel275,pixel276,pixel277,pixel278,pixel279,pixel280,pixel281,pixel282,pixel283,pixel284,pixel285,pixel286,pixel287,pixel288,pixel289,pixel290,pixel291,pixel292,pixel293,pixel294,pixel295,pixel296,pixel297,pixel298,pixel299,pixel300,pixel301,pixel302,pixel303,pixel304,pixel305,pixel306,pixel307,pixel308,pixel309,pixel310,pixel311,pixel312,pixel313,pixel314,pixel315,pixel316,pixel317,pixel318,pixel319,pixel320,pixel321,pixel322,pixel323,pixel324,pixel325,pixel326,pixel327,pixel328,pixel329,pixel330,pixel331,pixel332,pixel333,pixel334,pixel335,pixel336,pixel337,pixel338,pixel339,pixel340,pixel341,pixel342,pixel343,pixel344,pixel345,pixel346,pixel347,pixel348,pixel349,pixel350,pixel351,pixel352,pixel353,pixel354,pixel355,pixel356,pixel357,pixel358,pixel359,pixel360,pixel361,pixel362,pixel363,pixel364,pixel365,pixel366,pixel367,pixel368,pixel369,pixel370,pixel371,pixel372,pixel373,pixel374,pixel375,pixel376,pixel377,pixel378,pixel379,pixel380,pixel381,pixel382,pixel383,pixel384,pixel385,pixel386,pixel387,pixel388,pixel389,pixel390,pixel391,pixel392,pixel393,pixel394,pixel395,pixel396,pixel397,pixel398,pixel399,pixel400,pixel401,pixel402,pixel403,pixel404,pixel405,pixel406,pixel407,pixel408,pixel409,pixel410,pixel411,pixel412,pixel413,pixel414,pixel415,pixel416,pixel417,pixel418,pixel419,pixel420,pixel421,pixel422,pixel423,pixel424,pixel425,pixel426,pixel427,pixel428,pixel429,pixel430,pixel431,pixel432,pixel433,pixel434,pixel435,pixel436,pixel437,pixel438,pixel439,pixel440,pixel441,pixel442,pixel443,pixel444,pixel445,pixel446,pixel447,pixel448,pixel449,pixel450,pixel451,pixel452,pixel453,pixel454,pixel455,pixel456,pixel457,pixel458,pixel459,pixel460,pixel461,pixel462,pixel463,pixel464,pixel465,pixel466,pixel467,pixel468,pixel469,pixel470,pixel471,pixel472,pixel473,pixel474,pixel475,pixel476,pixel477,pixel478,pixel479,pixel480,pixel481,pixel482,pixel483,pixel484,pixel485,pixel486,pixel487,pixel488,pixel489,pixel490,pixel491,pixel492,pixel493,pixel494,pixel495,pixel496,pixel497,pixel498,pixel499,pixel500,pixel501,pixel502,pixel503,pixel504,pixel505,pixel506,pixel507,pixel508,pixel509,pixel510,pixel511,pixel512,pixel513,pixel514,pixel515,pixel516,pixel517,pixel518,pixel519,pixel520,pixel521,pixel522,pixel523,pixel524,pixel525,pixel526,pixel527,pixel528,pixel529,pixel530,pixel531,pixel532,pixel533,pixel534,pixel535,pixel536,pixel537,pixel538,pixel539,pixel540,pixel541,pixel542,pixel543,pixel544,pixel545,pixel546,pixel547,pixel548,pixel549,pixel550,pixel551,pixel552,pixel553,pixel554,pixel555,pixel556,pixel557,pixel558,pixel559,pixel560,pixel561,pixel562,pixel563,pixel564,pixel565,pixel566,pixel567,pixel568,pixel569,pixel570,pixel571,pixel572,pixel573,pixel574,pixel575,pixel576,pixel577,pixel578,pixel579,pixel580,pixel581,pixel582,pixel583,pixel584,pixel585,pixel586,pixel587,pixel588,pixel589,pixel590,pixel591,pixel592,pixel593,pixel594,pixel595,pixel596,pixel597,pixel598,pixel599,pixel600,pixel601,pixel602,pixel603,pixel604,pixel605,pixel606,pixel607,pixel608,pixel609,pixel610,pixel611,pixel612,pixel613,pixel614,pixel615,pixel616,pixel617,pixel618,pixel619,pixel620,pixel621,pixel622,pixel623,pixel624,pixel625,pixel626,pixel627,pixel628,pixel629,pixel630,pixel631,pixel632,pixel633,pixel634,pixel635,pixel636,pixel637,pixel638,pixel639,pixel640,pixel641,pixel642,pixel643,pixel644,pixel645,pixel646,pixel647,pixel648,pixel649,pixel650,pixel651,pixel652,pixel653,pixel654,pixel655,pixel656,pixel657,pixel658,pixel659,pixel660,pixel661,pixel662,pixel663,pixel664,pixel665,pixel666,pixel667,pixel668,pixel669,pixel670,pixel671,pixel672,pixel673,pixel674,pixel675,pixel676,pixel677,pixel678,pixel679,pixel680,pixel681,pixel682,pixel683,pixel684,pixel685,pixel686,pixel687,pixel688,pixel689,pixel690,pixel691,pixel692,pixel693,pixel694,pixel695,pixel696,pixel697,pixel698,pixel699,pixel700,pixel701,pixel702,pixel703,pixel704,pixel705,pixel706,pixel707,pixel708,pixel709,pixel710,pixel711,pixel712,pixel713,pixel714,pixel715,pixel716,pixel717,pixel718,pixel719,pixel720,pixel721,pixel722,pixel723,pixel724,pixel725,pixel726,pixel727,pixel728,pixel729,pixel730,pixel731,pixel732,pixel733,pixel734,pixel735,pixel736,pixel737,pixel738,pixel739,pixel740,pixel741,pixel742,pixel743,pixel744,pixel745,pixel746,pixel747,pixel748,pixel749,pixel750,pixel751,pixel752,pixel753,pixel754,pixel755,pixel756,pixel757,pixel758,pixel759,pixel760,pixel761,pixel762,pixel763,pixel764,pixel765,pixel766,pixel767,pixel768,pixel769,pixel770,pixel771,pixel772,pixel773,pixel774,pixel775,pixel776,pixel777,pixel778,pixel779,pixel780,pixel781,pixel782,pixel783,pixel784\n",
            "\n",
            "Each subsequent line (data points) look like this:\n",
            "3,107,118,127,134,139,143,146,150,153,156,158,160,163,165,159,166,168,170,170,171,171,171,172,171,171,170,170,169,111,121,129,135,141,144,148,151,154,157,160,163,164,170,119,152,171,171,170,171,172,172,172,172,172,171,171,170,113,123,131,137,142,145,150,152,155,158,161,163,164,172,105,142,170,171,171,171,172,172,173,173,172,171,171,171,116,125,133,139,143,146,151,153,156,159,162,163,167,167,95,144,171,172,172,172,172,172,173,173,173,172,172,171,117,126,134,140,145,149,153,156,158,161,163,164,175,156,87,154,172,173,173,173,173,173,174,174,174,173,172,172,119,128,136,142,146,150,153,156,159,163,165,164,184,148,89,164,172,174,174,174,174,175,175,174,175,174,173,173,122,130,138,143,147,150,154,158,162,165,166,172,181,128,94,170,173,175,174,175,176,177,177,177,177,175,175,174,122,132,139,145,149,152,156,160,163,165,166,181,172,103,113,175,176,178,178,179,179,179,179,178,179,177,175,174,125,134,141,147,150,153,157,161,164,167,168,184,179,116,126,165,176,179,180,180,181,180,180,180,179,178,177,176,128,135,142,148,152,154,158,162,165,168,170,187,180,156,161,124,143,179,178,178,181,182,181,180,181,180,179,179,129,136,144,150,153,155,159,163,166,169,172,187,184,153,102,117,110,175,169,154,182,183,183,182,182,181,181,179,131,138,145,150,155,157,161,165,168,174,190,189,175,146,94,97,113,151,158,129,184,184,184,184,183,183,182,180,131,139,146,151,155,159,163,167,175,182,179,171,159,114,102,89,121,136,136,96,172,186,186,185,185,184,182,181,131,140,147,154,157,160,164,179,186,191,187,180,157,100,88,84,108,111,126,90,120,186,187,187,186,185,184,182,133,141,149,155,158,160,174,201,189,165,151,143,146,120,87,78,87,76,108,98,96,181,188,187,186,186,185,183,133,141,150,156,160,161,179,197,174,135,99,72,95,134,97,72,74,68,116,105,108,187,189,187,187,186,186,185,134,143,151,156,161,163,179,194,156,110,74,42,52,139,94,67,75,75,118,106,129,189,191,190,188,188,187,186,135,144,152,158,163,163,177,193,161,122,84,43,71,134,81,57,71,88,112,98,157,193,193,192,190,190,189,188,136,144,152,158,162,163,176,192,164,128,98,62,60,100,71,76,96,101,105,95,174,195,194,194,194,193,191,190,137,145,152,159,164,165,178,191,164,135,113,82,59,87,98,111,120,108,97,108,190,196,195,195,194,193,193,192,139,146,154,160,164,165,175,186,163,139,112,85,67,102,126,133,126,105,104,176,197,198,197,196,195,195,194,193,138,147,155,161,165,167,172,186,163,137,107,87,76,106,122,125,117,96,156,199,199,200,198,196,196,195,195,194,139,148,156,163,166,168,172,180,158,131,108,99,86,108,118,116,103,107,191,202,201,200,200,200,199,197,198,196,140,149,157,164,168,167,177,178,155,131,118,105,87,100,106,100,96,164,202,202,202,202,202,201,200,199,199,198,140,150,157,165,167,170,181,175,152,130,115,98,82,85,90,99,165,202,203,204,203,203,202,202,201,201,200,200,142,150,159,165,170,191,173,157,144,119,97,84,79,79,91,172,202,203,203,205,204,204,204,203,202,202,201,200,142,151,160,165,188,190,187,150,119,109,85,79,79,78,137,203,205,206,206,207,207,206,206,204,205,204,203,202,142,151,160,172,196,188,188,190,135,96,86,77,77,79,176,205,207,207,207,207,207,207,206,206,206,204,203,202\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "with open(TRAINING_FILE) as training_file:\n",
        "  line = training_file.readline()\n",
        "  print(f\"First line (header) looks like this:\\n{line}\")\n",
        "  line = training_file.readline()\n",
        "  print(f\"Each subsequent line (data points) look like this:\\n{line}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08d6254e",
      "metadata": {
        "id": "08d6254e"
      },
      "source": [
        "As you can see, each file includes a header (the first line) and each subsequent data point is represented as a line that contains 785 values. \n",
        "\n",
        "The first value is the label (the numeric representation of each letter) and the other 784 values are the value of each pixel of the image. Remember that the original images have a resolution of 28x28, which sums up to 784 pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4835085f",
      "metadata": {
        "id": "4835085f"
      },
      "source": [
        " ## Parsing the dataset\n",
        " \n",
        " Now complete the `parse_data_from_input` below.\n",
        "\n",
        " This function should be able to read a file passed as input and return 2 numpy arrays, one containing the labels and one containing the 28x28 representation of each image within the file. These numpy arrays should have type `float64`.\n",
        "\n",
        " A couple of things to keep in mind:\n",
        " \n",
        "- The first line contains the column headers, so you should ignore it.\n",
        "\n",
        "- Each successive line contains 785 comma-separated values between 0 and 255\n",
        "  - The first value is the label\n",
        "\n",
        "  - The rest are the pixel values for that picture\n",
        "\n",
        "  \n",
        "**Hint**:\n",
        "\n",
        "You have two options to solve this function. \n",
        "  \n",
        "   - 1. One is to use `csv.reader` and create a for loop that reads from it, if you take this approach take this into consideration:\n",
        "\n",
        "        - `csv.reader` returns an iterable that returns a row of the csv file in each iteration.\n",
        "    Following this convention, row[0] has the label and row[1:] has the 784 pixel values.\n",
        "\n",
        "        - To reshape the arrays (going from 784 to 28x28), you can use functions such as [`np.array_split`](https://numpy.org/doc/stable/reference/generated/numpy.array_split.html) or [`np.reshape`](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html).\n",
        "\n",
        "        - For type conversion of the numpy arrays, use the method [`np.ndarray.astype`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html).\n",
        "\n",
        "\n",
        "   - 2. The other one is to use `np.loadtxt`. You can find the documentation [here](https://numpy.org/doc/stable/reference/generated/numpy.loadtxt.html).\n",
        "   \n",
        "   \n",
        "Regardless of the method you chose, your function should finish its execution in under 1 minute. If you see that your function is taking a long time to run, try changing your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9a287df1",
      "metadata": {
        "cellView": "code",
        "id": "9a287df1",
        "lines_to_next_cell": 2,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# GRADED FUNCTION: parse_data_from_input\n",
        "def parse_data_from_input(filename):\n",
        "  \"\"\"\n",
        "  Parses the images and labels from a CSV file\n",
        "  \n",
        "  Args:\n",
        "    filename (string): path to the CSV file\n",
        "    \n",
        "  Returns:\n",
        "    images, labels: tuple of numpy arrays containing the images and labels\n",
        "  \"\"\"\n",
        "  labels = []\n",
        "  images = []\n",
        "\n",
        "  with open(filename) as file:\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Use csv.reader, passing in the appropriate delimiter\n",
        "    # Remember that csv.reader can be iterated and returns one line in each iteration\n",
        "    csv_reader = csv.reader(file, delimiter=',')\n",
        "    next(csv_reader)  # Skip header\n",
        "    #labels = None\n",
        "    #images = None\n",
        "    for row in csv_reader:\n",
        "       label = float(row[0])\n",
        "       pixel_values = [float(p) for p in row[1:]]\n",
        "       image = np.array(pixel_values).astype(np.float64)\n",
        "       image = np.reshape(image, (28, 28))\n",
        "       labels.append(label)\n",
        "       images.append(image)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "  return  np.array(labels).astype(np.float64), np.array(images).astype(np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5fd73791",
      "metadata": {
        "id": "5fd73791",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86a95eb-d7d6-448a-fa30-02820d1ca93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images has shape: (27455,) and dtype: float64\n",
            "Training labels has shape: (27455, 28, 28, 1) and dtype: float64\n",
            "Validation images has shape: (7172,) and dtype: float64\n",
            "Validation labels has shape: (7172, 28, 28, 1) and dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your function\n",
        "training_images, training_labels = parse_data_from_input(TRAINING_FILE)\n",
        "validation_images, validation_labels = parse_data_from_input(VALIDATION_FILE)\n",
        "\n",
        "print(f\"Training images has shape: {training_images.shape} and dtype: {training_images.dtype}\")\n",
        "print(f\"Training labels has shape: {training_labels.shape} and dtype: {training_labels.dtype}\")\n",
        "print(f\"Validation images has shape: {validation_images.shape} and dtype: {validation_images.dtype}\")\n",
        "print(f\"Validation labels has shape: {validation_labels.shape} and dtype: {validation_labels.dtype}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c462ef51",
      "metadata": {
        "id": "c462ef51"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Training images has shape: (27455, 28, 28) and dtype: float64\n",
        "Training labels has shape: (27455,) and dtype: float64\n",
        "Validation images has shape: (7172, 28, 28) and dtype: float64\n",
        "Validation labels has shape: (7172,) and dtype: float64\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3275c697",
      "metadata": {
        "id": "3275c697"
      },
      "source": [
        "## Visualizing the numpy arrays\n",
        "\n",
        "Now that you have converted the initial csv data into a format that is compatible with computer vision tasks, take a moment to actually see how the images of the dataset look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d25f2fc4",
      "metadata": {
        "id": "d25f2fc4",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "205523e5-8cbb-45c2-e73a-d5f37aa04a26"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d69de7e6af53>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mplot_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-d69de7e6af53>\u001b[0m in \u001b[0;36mplot_categories\u001b[0;34m(training_images, training_labels)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_to_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Greys_r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36marray_to_img\u001b[0;34m(x, data_format, scale, dtype)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0;34m\"Expected image array to have rank 3 (single image). \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0;34mf\"Got array with shape: {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected image array to have rank 3 (single image). Got array with shape: (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x1500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plot a sample of 10 images from the training set\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
        "\n",
        "def plot_categories(training_images, training_labels):\n",
        "  fig, axes = plt.subplots(1, 10, figsize=(16, 15))\n",
        "  axes = axes.flatten()\n",
        "  letters = list(string.ascii_lowercase)\n",
        "\n",
        "  for k in range(10):\n",
        "    img = training_images[k]\n",
        "    img = np.expand_dims(img, axis=-1)\n",
        "    img = array_to_img(img)\n",
        "    ax = axes[k]\n",
        "    ax.imshow(img, cmap=\"Greys_r\")\n",
        "    ax.set_title(f\"{letters[int(training_labels[k])]}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "plot_categories(training_images, training_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "387456dc",
      "metadata": {
        "id": "387456dc"
      },
      "source": [
        "## Creating the generators for the CNN\n",
        "\n",
        "Now that you have successfully organized the data in a way that can be easily fed to Keras' `ImageDataGenerator`, it is time for you to code the generators that will yield batches of images, both for training and validation. For this complete the `train_val_generators` function below.\n",
        "\n",
        "Some important notes:\n",
        "\n",
        "- The images in this dataset come in the same resolution so you don't need to set a custom `target_size` in this case. In fact, you can't even do so because this time you will not be using the `flow_from_directory` method (as in previous assignments). Instead you will use the [`flow`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow) method.\n",
        "- You need to add the \"color\" dimension to the numpy arrays that encode the images. These are black and white images, so this new dimension should have a size of 1 (instead of 3, which is used when dealing with colored images). Take a look at the function [`np.expand_dims`](https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html) for this."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images = np.expand_dims(training_images, axis=-1)\n",
        "validation_images = np.expand_dims(validation_images, axis=-1)\n",
        "print(training_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTjKohv8QHIF",
        "outputId": "167d84ef-5597-4bb3-ed01-5b690871cebe"
      },
      "id": "fTjKohv8QHIF",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27455, 1, 1, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "612e8e4c",
      "metadata": {
        "cellView": "code",
        "id": "612e8e4c",
        "lines_to_next_cell": 2,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "import numpy as np\n",
        "# GRADED FUNCTION: train_val_generators\n",
        "def train_val_generators(training_images, training_labels, validation_images, validation_labels):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    training_images (array): parsed images from the train CSV file\n",
        "    training_labels (array): parsed labels from the train CSV file\n",
        "    validation_images (array): parsed images from the test CSV file\n",
        "    validation_labels (array): parsed labels from the test CSV file\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # In this section you will have to add another dimension to the data\n",
        "  # So, for example, if your array is (10000, 28, 28)\n",
        "  # You will need to make it (10000, 28, 28, 1)\n",
        "  # Hint: np.expand_dims\n",
        "  training_images = np.expand_dims(training_images, axis=-1)\n",
        "  validation_images = np.expand_dims(validation_images, axis=-1)\n",
        "  #image = np.expand_dims(image, axis=-1)  # Add extra dimension\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class \n",
        "  # Don't forget to normalize pixel values \n",
        "  # and set arguments to augment the images (if desired)\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                       rotation_range=20,\n",
        "                                       width_shift_range=0.1,\n",
        "                                       height_shift_range=0.1,\n",
        "                                       zoom_range=0.2,\n",
        "                                       horizontal_flip=True)\n",
        "\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow method\n",
        "  train_generator = train_datagen.flow(x=training_images,\n",
        "                                       y=training_labels,\n",
        "                                       batch_size=32) \n",
        "\n",
        "  \n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  # Remember that validation data should not be augmented\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow method\n",
        "  validation_generator = validation_datagen.flow(x=validation_images,\n",
        "                                                 y=validation_labels,\n",
        "                                                 batch_size=32) \n",
        "\n",
        "  ### END CODE HERE\n",
        "\n",
        "  return train_generator, validation_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ca82557c",
      "metadata": {
        "id": "ca82557c",
        "tags": [
          "graded"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "8c274bf9-abf1-4e20-e103-bc190d4fc8b6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-83accedbbcb2>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Test your generators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_val_generators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Images of training generator have shape: {train_generator.x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-edc47f4b09f1>\u001b[0m in \u001b[0;36mtrain_val_generators\u001b[0;34m(training_images, training_labels, validation_images, validation_labels)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;31m# Pass in the appropriate arguments to the flow method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   train_generator = train_datagen.flow(x=training_images,\n\u001b[0m\u001b[1;32m     40\u001b[0m                                        \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                                        batch_size=32) \n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \"\"\"\n\u001b[0;32m-> 1545\u001b[0;31m         return NumpyArrayIterator(\n\u001b[0m\u001b[1;32m   1546\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_misc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_misc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0;34m\"Input data in `NumpyArrayIterator` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0;34m\"should have rank 4. You passed an array \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: ('Input data in `NumpyArrayIterator` should have rank 4. You passed an array with shape', (27455, 1, 1, 1, 1, 1))"
          ]
        }
      ],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(training_images, training_labels, validation_images, validation_labels)\n",
        "\n",
        "print(f\"Images of training generator have shape: {train_generator.x.shape}\")\n",
        "print(f\"Labels of training generator have shape: {train_generator.y.shape}\")\n",
        "print(f\"Images of validation generator have shape: {validation_generator.x.shape}\")\n",
        "print(f\"Labels of validation generator have shape: {validation_generator.y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "787a2ec0",
      "metadata": {
        "id": "787a2ec0"
      },
      "source": [
        "**Expected Output:**\n",
        "```\n",
        "Images of training generator have shape: (27455, 28, 28, 1)\n",
        "Labels of training generator have shape: (27455,)\n",
        "Images of validation generator have shape: (7172, 28, 28, 1)\n",
        "Labels of validation generator have shape: (7172,)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a125c368",
      "metadata": {
        "id": "a125c368"
      },
      "source": [
        "## Coding the CNN\n",
        "\n",
        "One last step before training is to define the architecture of the model that will be trained.\n",
        "\n",
        "Complete the `create_model` function below. This function should return a Keras' model that uses the `Sequential` or the `Functional` API.\n",
        "\n",
        "The last layer of your model should have a number of units that corresponds to the number of possible categories, as well as the correct activation function.\n",
        "\n",
        "Aside from defining the architecture of the model, you should also compile it so make sure to use a `loss` function that is suitable for multi-class classification.\n",
        "\n",
        "**Note that you should use no more than 2 Conv2D and 2 MaxPooling2D layers to achieve the desired performance.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb9eeb74",
      "metadata": {
        "cellView": "code",
        "id": "eb9eeb74",
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# grader-required-cell\n",
        "\n",
        "def create_model():\n",
        "\n",
        "  ### START CODE HERE       \n",
        "\n",
        "  # Define the model\n",
        "  # Use no more than 2 Conv2D and 2 MaxPooling2D\n",
        "  model = None\n",
        "  \n",
        "\n",
        "  model.compile(optimizer = None,\n",
        "                loss = None,\n",
        "                metrics=[None])\n",
        "\n",
        "  ### END CODE HERE       \n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b337357c",
      "metadata": {
        "id": "b337357c",
        "lines_to_next_cell": 2,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Save your model\n",
        "model = create_model()\n",
        "\n",
        "# Train your model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cb937bc",
      "metadata": {
        "id": "7cb937bc"
      },
      "source": [
        "Now take a look at your training history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07b2b989",
      "metadata": {
        "id": "07b2b989",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Plot the chart for accuracy and loss on both training and validation\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "358e81a8",
      "metadata": {
        "id": "358e81a8"
      },
      "source": [
        "You will not be graded based on the accuracy of your model but try making it as high as possible for both training and validation, as an optional exercise, **after submitting your notebook for grading**.\n",
        "\n",
        "A reasonable benchmark is to achieve over 99% accuracy for training and over 95% accuracy for validation within 15 epochs. Try tweaking your model's architecture or the augmentation techniques to see if you can achieve these levels of accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f54f3dd",
      "metadata": {
        "id": "5f54f3dd"
      },
      "source": [
        "## Download your notebook for grading\n",
        "\n",
        "You will need to submit your solution notebook for grading. The following code cells will check if this notebook's grader metadata (i.e. hidden data in the notebook needed for grading) is not modified by your workspace. This will ensure that the autograder can evaluate your code properly. Depending on its output, you will either:\n",
        "\n",
        "* *if the metadata is intact*: Download the current notebook. Click on the File tab on the upper left corner of the screen then click on `Download -> Download .ipynb.` You can name it anything you want as long as it is a valid `.ipynb` (jupyter notebook) file.\n",
        "<br>\n",
        "\n",
        "* *if the metadata is missing*: A new notebook with your solutions will be created on this Colab workspace. It should be downloaded automatically and you can submit that to the grader. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d75a30a",
      "metadata": {
        "id": "9d75a30a"
      },
      "outputs": [],
      "source": [
        "# Download metadata checker\n",
        "!wget -nc https://storage.googleapis.com/tensorflow-1-public/colab_metadata_checker.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23fd2b0",
      "metadata": {
        "id": "b23fd2b0"
      },
      "outputs": [],
      "source": [
        "import colab_metadata_checker\n",
        "\n",
        "# Please see the output of this cell to see which file you need to submit to the grader\n",
        "colab_metadata_checker.run('C2W4_Assignment_fixed.ipynb')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea864ce9",
      "metadata": {
        "id": "ea864ce9"
      },
      "source": [
        "**Please disregard the following note if the notebook metadata is detected**\n",
        "\n",
        "_Note: Just in case the download fails for the second point above, you can also do these steps:_\n",
        "* _Click the Folder icon on the left side of this screen to open the File Manager._\n",
        "* _Click the Folder Refresh icon in the File Manager to see the latest files in the workspace. You should see a file ending with a `_fixed.ipynb`._\n",
        "* _Right-click on that file to save locally and submit it to the grader._\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ebe23be",
      "metadata": {
        "id": "3ebe23be"
      },
      "source": [
        "**Congratulations on finishing this week's assignment!**\n",
        "\n",
        "You have successfully implemented a convolutional neural network that is able to perform multi-class classification tasks! Nice job!\n",
        "\n",
        "**Keep it up!**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}